# Теоретический минимум по машинному обучению (Поток Воронцов К.В. и Грабовой А.В.)

## Решающие деревья
* Что такое решающее дерево и как оно работает?
* Какие критерии для выбора параметров в узлах дерева, какой из какого следует и почему.
* Какие гиперпараметры регулируют сложность решающего дерева?
* Как решающие деревья обрабатывают задачи регрессии?
* В чем разница между классификационным и регрессионным деревом?

## Логистическая регрессия
* Что такое логистическая регрессия и какую задачу она решает?
* Как выглядит функция потерь в логистической регрессии?
* Как оптимизируются параметры в логистической регрессии?
* Как обобщить логистическую регрессию на многоклассовую классификацию?
* Чем логистическая регрессия отличается от линейной?
* Какие метрики используются для оценки классификации?
* Что такое матрица ошибок?

## SVM (Support Vector Machines)
* В чем основная идея SVM?
* Как строится разделяющая гиперплоскость в SVM?
* Зачем в SVM используются ядра?
* Назовите основные ядра в SVM.
* Как SVM обобщается для задач регрессии?
* Как работает метод опорных векторов для несбалансированных данных?  

## Линейная регрессия
* Как работает линейная регрессия?
* Как находится оптимальное значение параметров?
* В чем проблема мультиколлинеарности и как ее решают?
* Объясните вероятностную интерпретацию регуляризации в случае Lasso и Ridge.
* Чем Lasso отличается от Ridge регуляризации?
* Как оценивать качество регрессионных моделей?

## Ансамблирование моделей
* Назовите основные виды ансамблирования и их основное отличие.
* Когда лучше использовать бэггинг, а когда — бустинг?
* Приведите примеры алгоритмов бустинга.
* Приведите примеры алгоритмов бэггинга.
* Как работает алгоритм Random Forest?
* Объясните принцип работы XGBoost.
* Что такое "ансамблевое усреднение"?  
* Как работает метод Stacking в ансамблировании?
* Как работает метод случайного подпространства (Random Subspace) в бэггинге?  

## Отбор признаков
* Какие методы отбора признаков вы знаете?
* Почему L1-регуляризация зануляет некоторые параметры?
* Как работает жадный алгоритм Add-Del для отбора признаков?
* Объясните критерий Фишера для отбора признаков.
* Как метод Белсли и SVD помогают бороться с мультиколлинеарностью?

## Деление выборки
* В чем проблемы случайного деления выборки на обучение и контроль?
* Как стратификация решает проблему несбалансированных данных?
* Что такое утечка данных при разделении выборки?

## Нейронные сети
*. Что такое полносвязная нейронная сеть?
* Назовите популярные функции активации, в чем их отличие.
* Какие проблемы возникают в полносвязных сетях?
* Что такое dropout, чем отличается в обучении и в контроле?
* Что такое BatchNorm, чем отличается в обучении и в контроле?
* Что такое паралич нейронной сети и как его избежать?
* Опишите идею обратного распространения ошибки в нейросетях.
* Опишите идею прямого метода дифференцирования в нейросетях.
* Что такое градиентный спуск и его варианты?

## RNN, LSTM, GRU
* Как работают рекуррентные нейронные сети?
* Какие проблемы возникают при обучении RNN?
* Как LSTM и GRU решают эти проблемы и какие проблемы?
* Что такое Gradient Clipping и зачем он нужен?

## Сверточные сети (CNN)
* В чем идея сверточных нейронных сетей?
* Что такое операция свертки, какие у нее есть параметры?
* Какие слои кроме сверточных используются в CNN?
* В чем особенность архитектуры ResNet?
* Как дообучать предобученные модели под конкретную задачу?

## Автокодировщики и GAN
* Что такое автокодировщик и зачем он нужен?
* Как линейный автокодировщик связан с PCA?
* Опишите принцип работы вариационного автокодировщика.
* Чем GAN отличается от автокодировщика?

## Обучение с подкреплением (RL)
* В чем основная идея обучения с подкреплением?
* Приведите пример задачи RL с байесовскими бандитами.
* Как решается задача заплыва?

## Активное обучение
* Какие проблемы решает активное обучение?
* Назовите методы активного обучения.  

## KNN (k-ближайших соседей)
* Как работает алгоритм KNN?  
* Какие гиперпараметры есть у KNN (k, метрика расстояния)?  
* Какие проблемы возникают при использовании KNN и как их решить?
* Как работает метод ближайших соседей для регрессии?  

## Кластеризация
* Назовите методы кластеризации, чем они отличаеются.
* Какие методы не требуют задания числа кластеров?
* Как работает EM-алгоритм в кластеризации?
* Как работает метод k-средних?  
* Что такое матрица смежности в кластеризации?  
* Как работает метод DBSCAN?  

## Тематическое моделирование
* Что такое тематическое моделирование и зачем оно нужно?
* Как EM-алгоритм используется в тематическом моделировании?
* Примеры регуляризаторов в тематических моделях.

## Ранжирование и поиск
* Зачем нужны ранжирующие системы?
* Как оценивают качество поисковых систем?

## Трансформеры
* Что такое attention?
* В чем отличие между self-attention и cross-attention?
* В чем отличие между transformer, gpt-like и bert-like моделями?
* На какие задачи обучался BERT в базовом варианте?

## Несортировано
* Что такое метод главных компонент?
* Что такое переобучение и как с ним бороться?
* В чем разница между параметрами и гиперпараметрами модели?
* Что такое кросс-валидация и зачем она нужна?
* Что такое ROC-кривая и AUC?
* Объясните разницу между байесовским и частотным подходами в ML.
* Наивный байесовский классификатор, что это такое?
* Что такое "проклятие размерности"?
* Как работает метод t-SNE для визуализации данных, в чем минусы?  
* Что такое обучение без учителя?  
* Какие задачи решает обучение с частичным привлечением учителя (semi-supervised)?  
* Что такое Transfer Learning? 
* Что такое "обучение с учителем" (supervised learning)?  
* Что такое "теория обучения" (bias-variance tradeoff)?  
